2018-03-07 10:42:06 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: HudongWiki)
2018-03-07 10:42:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'HudongWiki', 'CONCURRENT_REQUESTS': 128, 'COOKIES_ENABLED': False, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'mySpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Hudongwiki', 'REDIRECT_ENABLED': False, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HudongWiki.spiders']}
2018-03-07 10:42:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-03-07 10:42:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-03-07 10:42:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-03-07 10:42:07 [twisted] CRITICAL: Unhandled error in Deferred:
2018-03-07 10:42:07 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "D:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
  File "E:\disease_baike\HudongWiki\HudongWiki\pipelines.py", line 10, in __init__
    self.file = open('../data/your_baike.json', 'w')
FileNotFoundError: [Errno 2] No such file or directory: '../data/your_baike.json'
2018-03-07 10:44:39 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: HudongWiki)
2018-03-07 10:44:39 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'HudongWiki', 'CONCURRENT_REQUESTS': 128, 'COOKIES_ENABLED': False, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'mySpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Hudongwiki', 'REDIRECT_ENABLED': False, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HudongWiki.spiders']}
2018-03-07 10:44:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-03-07 10:44:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-03-07 10:44:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-03-07 10:44:40 [scrapy.middleware] INFO: Enabled item pipelines:
['HudongWiki.pipelines.HudongPipeline']
2018-03-07 10:44:40 [scrapy.core.engine] INFO: Spider opened
2018-03-07 10:44:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-03-07 10:44:40 [scrapy.core.scraper] ERROR: Error processing {'baseInfoKeyList': '中文名：##外文名：##拼 音：##解 释：##分 类：##用 途：',
 'baseInfoValueList': '月台##balcony##yuè tái##站台##岛式，侧式，港湾式，混合式等##古时用来赏月，现为候车台',
 'detail': '在古时建筑上，正房、正殿突出连着前阶的平台叫“月台”，月台是该建筑物的基础，也是它的组成部分。由于此类平台宽敞而通透，一般前无遮拦，故是看月亮的好地方，也就成了赏月之台。而现代的月台通常指进入火车站后方便旅客上火车的一段与铁轨平行的平台。',
 'image': 'http://a4.att.hudong.com/78/92/20300542517414139795923014468_s.jpg',
 'openTypeList': '交通##土木工程##建筑物##生活',
 'title': '月台',
 'url': 'http://www.baike.com/wiki/月台'}
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
TypeError: process_item() takes 2 positional arguments but 3 were given
2018-03-07 10:44:40 [scrapy.core.scraper] ERROR: Error processing {'baseInfoKeyList': '中文名：##出生日期：##性别：##英文名：##别名：##籍贯：##出生地：##民族：##国籍：##去世日期：##职业：##毕业院校：##代表作品：##家人：',
 'baseInfoValueList': '朱自清##1898年11月22日##男##Zhu '
                      'Ziqing##原名自华，号秋实，字佩弦##浙江绍兴##江苏东海县##汉族##中国##1948年8月12日##现代散文家、诗人、学者、民主战士##北京大学##《毁灭》、《背影》、《荷塘月色》、《欧游杂记》、《你我》、《伦敦杂记》##原配武钟谦，续弦陈竹隐，儿子朱闰生、朱迈先',
 'detail': '朱自清（1898.11.22－194808.12），原名自华，字佩弦，号秋实。浙江绍兴人，北京大学毕业，曾任清华大学中文系教授、系主任。中国现代诗人、散文作家。文笔清新，所著合编为朱自清全集。为中国现代散文增添了瑰丽的色彩，为建立中国现代散文全新的审美特征创造了具有中国民族特色的散文体制和风格；主要作品有《雪朝》、《踪迹》、《背影》、《春》、《欧游杂记》、《你我》、《精读指导举隅》、《略读指导举隅》、《国文教学》、《诗言志辨》、《新诗杂话》、《标准与尺度》、《论雅俗共赏》。',
 'image': 'http://a2.att.hudong.com/51/79/20200000013920144731796755652_s.jpg',
 'openTypeList': '人物##作家',
 'title': '朱自清',
 'url': 'http://www.baike.com/wiki/朱自清'}
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
TypeError: process_item() takes 2 positional arguments but 3 were given
2018-03-07 10:44:40 [scrapy.core.scraper] ERROR: Error processing {'baseInfoKeyList': '中文学名：##别名：##外文名：##拉丁学名：##二名法：##界：##门：##亚门：##纲：##亚纲：##目：##亚目：##科：##亚科：##属：##亚属：##种：##亚种：',
 'baseInfoValueList': '橘子##桔子##orange##Citrus reticulata##Citrus '
                      'reticulata##植物界##被子植物门(Angiospermae)##被子植物亚门 '
                      'Magnoliophyta##双子叶植物纲(Dicotyledoneae)也称木兰纲。##原始花被亚纲##无患子目(Sapindales)##芸香亚目##芸香科(Rutaceae)##柑橘亚科(Aurantioideae '
                      'Engl.)##柑橘属(Citrus Linn.)##柑橘亚属##橘 C. '
                      'reticulata##湖北、福建、浙江、江西、湖南、四川、广西',
 'detail': '橘子是多年生芸香科植物的果实，中国也是橘树的主要发源地之一。中国古人食用橘子，并且将野生橘树进行人工栽培，历史悠久 '
           '。橘子有好几种品种，但是常见的还是椪柑，它的果实外皮肥厚，内藏瓤瓣，由汁泡和种子构成。橘子属热带作物，主要种植于中国南方，橘子色彩鲜艳、酸甜可口，是秋冬季常见的美味佳果。橘子富含丰富的维生素c，对人体有着很大的好处。在中医里认为橘子是温性食物,易上火，所以不能多吃 '
           '。',
 'image': 'http://a2.att.hudong.com/74/70/20200000013920144732700753916_s.jpg',
 'openTypeList': '',
 'title': '橘子',
 'url': 'http://www.baike.com/wiki/橘子'}
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
TypeError: process_item() takes 2 positional arguments but 3 were given
2018-03-07 10:44:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-03-07 10:44:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 932,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 109855,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 3, 7, 2, 44, 40, 824850),
 'log_count/ERROR': 3,
 'log_count/INFO': 7,
 'response_received_count': 4,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 3, 7, 2, 44, 40, 203079)}
2018-03-07 10:44:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-03-07 10:50:57 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: HudongWiki)
2018-03-07 10:50:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'HudongWiki', 'CONCURRENT_REQUESTS': 128, 'COOKIES_ENABLED': False, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'mySpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Hudongwiki', 'REDIRECT_ENABLED': False, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HudongWiki.spiders']}
2018-03-07 10:50:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-03-07 10:50:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-03-07 10:50:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-03-07 10:50:57 [scrapy.middleware] INFO: Enabled item pipelines:
['HudongWiki.pipelines.HudongPipeline']
2018-03-07 10:50:57 [scrapy.core.engine] INFO: Spider opened
2018-03-07 10:50:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-03-07 10:50:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-03-07 10:50:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 932,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 109855,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 3, 7, 2, 50, 57, 767133),
 'item_scraped_count': 3,
 'log_count/INFO': 7,
 'response_received_count': 4,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 3, 7, 2, 50, 57, 191736)}
2018-03-07 10:50:57 [scrapy.core.engine] INFO: Spider closed (finished)
